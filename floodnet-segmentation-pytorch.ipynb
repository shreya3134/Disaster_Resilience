{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6826954,"sourceType":"datasetVersion","datasetId":3918166},{"sourceId":6829734,"sourceType":"datasetVersion","datasetId":3927012},{"sourceId":7950284,"sourceType":"datasetVersion","datasetId":4675398}],"dockerImageVersionId":30626,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install segmentation_models_pytorch","metadata":{"execution":{"iopub.status.busy":"2023-12-20T22:10:46.699469Z","iopub.execute_input":"2023-12-20T22:10:46.699903Z","iopub.status.idle":"2023-12-20T22:11:00.629016Z","shell.execute_reply.started":"2023-12-20T22:10:46.699869Z","shell.execute_reply":"2023-12-20T22:11:00.627446Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport os\nimport sys\nimport gc\nimport argparse\nimport torch.optim as optim\nimport numpy as np\nimport torch.nn as nn\nimport torch.backends.cudnn as cudnn\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom torchvision import transforms as T\nfrom torch.utils.data import Dataset\nfrom PIL import Image \nfrom torchvision.models.segmentation import deeplabv3_resnet50\nimport segmentation_models_pytorch as smp \n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device:', device, \"\\n\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-20T22:11:00.631426Z","iopub.execute_input":"2023-12-20T22:11:00.631819Z","iopub.status.idle":"2023-12-20T22:11:00.64057Z","shell.execute_reply.started":"2023-12-20T22:11:00.631782Z","shell.execute_reply":"2023-12-20T22:11:00.63952Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class FloodNetDataset_Labeled(Dataset):\n    \"\"\"\n            classes:\n            \n            \"background\",\n            \"building-flooded\",\n            \"building non-flooded\",\n            \"road flooded\",\n            \"road non-flooded\",\n            \"water\",\n            \"tree\",\n            \"vehicle\",\n            \"pool\",\n            \"grass\",\n            \n    \"\"\"\n\n    def __init__(\n        self, base_folder=\"/kaggle/input/floodnet-labeled\", transform=lambda x: x,  target_transform=lambda y: y\n    ) -> None:\n        super().__init__()\n        self.base_folder = base_folder\n        self.im_files = [f for f in os.listdir(self.base_folder) if f.endswith(\".jpg\")]\n        self.transform = transform\n        self.target_transform = target_transform\n\n    def __len__(self):\n        return len(self.im_files)\n\n    def __getitem__(self, index):\n        img_file = os.path.join(self.base_folder, self.im_files[index])\n        gt_file = img_file.replace(\".jpg\", \"_lab.png\")\n        img = Image.open(img_file)\n        label = Image.open(gt_file)\n        state = torch.get_rng_state()\n        img = self.transform(img)\n        torch.set_rng_state(state)\n        label = self.target_transform(label)\n\n        return img, label","metadata":{"execution":{"iopub.status.busy":"2023-12-20T22:11:00.642072Z","iopub.execute_input":"2023-12-20T22:11:00.642403Z","iopub.status.idle":"2023-12-20T22:11:00.659962Z","shell.execute_reply.started":"2023-12-20T22:11:00.642369Z","shell.execute_reply":"2023-12-20T22:11:00.658927Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class FloodNetDataset_Unlabeled(Dataset):\n    def __init__(self, base_folder, transform=lambda x: x) -> None:\n        super().__init__()\n        self.base_folder = base_folder\n        self.im_files = [f for f in os.listdir(self.base_folder) if f.endswith(\".jpg\")]\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.im_files)\n\n    def __getitem__(self, index):\n        img_file = os.path.join(self.base_folder, self.im_files[index])\n        img = Image.open(img_file)\n        img_aug = self.transform(img)\n        return img_aug","metadata":{"execution":{"iopub.status.busy":"2023-12-20T22:11:00.663025Z","iopub.execute_input":"2023-12-20T22:11:00.663537Z","iopub.status.idle":"2023-12-20T22:11:00.67184Z","shell.execute_reply.started":"2023-12-20T22:11:00.663491Z","shell.execute_reply":"2023-12-20T22:11:00.670821Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def dice_coef(y_pred, y_true, epsilon=1e-7):\n    dice = []\n    \n    # compute for each class \n    classes = int(np.max(np.unique(y_true.detach().cpu().numpy())))\n    for num_class in range(1, classes):\n        target = (y_true == num_class)\n        pred = (y_pred == num_class)\n        \n        intersect = (target * pred).sum()\n        base = (target).sum() + (pred).sum()\n        del(target); del(pred)\n        \n        score = (2 * intersect + epsilon) / (base + epsilon)\n        dice.append(score)\n        del(intersect); del(base)\n    \n    return (sum(dice) / len(dice)).item()","metadata":{"execution":{"iopub.status.busy":"2023-12-20T22:11:00.673187Z","iopub.execute_input":"2023-12-20T22:11:00.673592Z","iopub.status.idle":"2023-12-20T22:11:00.686136Z","shell.execute_reply.started":"2023-12-20T22:11:00.673561Z","shell.execute_reply":"2023-12-20T22:11:00.685023Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# UNET\n\nclass conv_block(nn.Module):\n\n    def __init__(self, ch_in, ch_out, norm_layer=None):\n        super(conv_block, self).__init__()\n        if norm_layer is None:\n            norm_layer = nn.BatchNorm2d\n\n        self.conv = nn.Sequential(\n            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n            #nn.BatchNorm2d(ch_out),\n            norm_layer(num_features=ch_out),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n            #nn.BatchNorm2d(ch_out),\n            norm_layer(num_features=ch_out),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        x = self.conv(x)\n        return x\n\n\nclass up_conv(nn.Module):\n    def __init__(self, ch_in, ch_out, norm_layer=None):\n        super(up_conv, self).__init__()\n        if norm_layer is None:\n            norm_layer = nn.BatchNorm2d\n        self.up = nn.Sequential(\n            nn.Upsample(scale_factor=2),\n            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n            norm_layer(num_features=ch_out),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        x = self.up(x)\n        return x\n\n\nclass U_Net(nn.Module):\n    def __init__(self, img_ch=3, output_ch=1, norm_layer=None):\n        super(U_Net, self).__init__()\n\n        self.Maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        self.Conv1 = conv_block(ch_in=img_ch, ch_out=64, norm_layer=norm_layer)\n        self.Conv2 = conv_block(ch_in=64, ch_out=128, norm_layer=norm_layer)\n        self.Conv3 = conv_block(ch_in=128, ch_out=256, norm_layer=norm_layer)\n        self.Conv4 = conv_block(ch_in=256, ch_out=512, norm_layer=norm_layer)\n        self.Conv5 = conv_block(ch_in=512, ch_out=1024, norm_layer=norm_layer)\n\n        self.Up5 = up_conv(ch_in=1024, ch_out=512, norm_layer=norm_layer)\n        self.Up_conv5 = conv_block(ch_in=1024, ch_out=512, norm_layer=norm_layer)\n\n        self.Up4 = up_conv(ch_in=512, ch_out=256, norm_layer=norm_layer)\n        self.Up_conv4 = conv_block(ch_in=512, ch_out=256, norm_layer=norm_layer)\n\n        self.Up3 = up_conv(ch_in=256, ch_out=128, norm_layer=norm_layer)\n        self.Up_conv3 = conv_block(ch_in=256, ch_out=128, norm_layer=norm_layer)\n\n        self.Up2 = up_conv(ch_in=128, ch_out=64, norm_layer=norm_layer)\n        self.Up_conv2 = conv_block(ch_in=128, ch_out=64, norm_layer=norm_layer)\n\n        self.Conv_1x1 = nn.Conv2d(64, output_ch, kernel_size=1, stride=1, padding=0)\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        # encoding path\n        x1 = self.Conv1(x)\n        # print(\"U_Net forward:\", type(x))\n        # print(\"U_Net forward:\", x.shape)\n        x2 = self.Maxpool(x1)\n        x2 = self.Conv2(x2)\n\n        x3 = self.Maxpool(x2)\n        x3 = self.Conv3(x3)\n\n        x4 = self.Maxpool(x3)\n        x4 = self.Conv4(x4)  # self.Conv4 = conv_block(ch_in=256,ch_out=512)\n\n        x5 = self.Maxpool(x4)\n        x5 = self.Conv5(x5)  # self.Conv5 = conv_block(ch_in=512,ch_out=1024)\n        # print(\"U_Net forward:\", \"encoding\", type(x5))\n        # print(\"U_Net forward:\", \"encoding\", x5.shape)\n\n        # decoding + concat path\n        d5 = self.Up5(x5)  # self.Up5 = up_conv(ch_in=1024,ch_out=512)\n        d5 = torch.cat((x4, d5), dim=1)\n\n        d5 = self.Up_conv5(d5)\n\n        d4 = self.Up4(d5)\n        d4 = torch.cat((x3, d4), dim=1)\n        d4 = self.Up_conv4(d4)\n\n        d3 = self.Up3(d4)\n        d3 = torch.cat((x2, d3), dim=1)\n        d3 = self.Up_conv3(d3)\n\n        d2 = self.Up2(d3)\n        d2 = torch.cat((x1, d2), dim=1)\n        d2 = self.Up_conv2(d2)\n\n        d1 = self.Conv_1x1(d2)\n\n        # print(\"U_Net forward:\", \"dencoding\", type(d1))\n        # print(\"U_Net forward:\", \"dencoding shape\", d1.shape)\n        return d1","metadata":{"execution":{"iopub.status.busy":"2023-12-20T22:11:00.688096Z","iopub.execute_input":"2023-12-20T22:11:00.688595Z","iopub.status.idle":"2023-12-20T22:11:00.715541Z","shell.execute_reply.started":"2023-12-20T22:11:00.688511Z","shell.execute_reply":"2023-12-20T22:11:00.71422Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# define parmeters and folders\nclass Opt():\n    def __init__(self):\n        self.learning_rate = 0.001\n        self.mean = [-0.2417,  0.8531,  0.1789]\n        self.std = [0.9023, 1.1647, 1.3271] \n        self.print_freq = 20\n        self.name_net = 'unet'  # pspnet, deeplab\n        self.batch_size = 4\n        self.num_workers = 2\n        self.epochs = 15\n        self.supervised_epochs = 10\n        self.num_classes = 10\n        self.resize_height = 256\n        self.resize_width = 256\n        self.b_factor = 1\n        self.alpha = 1\n        self.load_saved_model = False\n        self.threshold_val_dice = 0.3\n\n        # Folders\n        self.path_to_pretrained_model = '...' # set path to pretrained model if load_saved_model = True, format: name_best.pth\n        self.project_folder = '/kaggle/working/'\n        self.labeled_data_folder = '/kaggle/input/floodnet-labeled/segmentation kaggle/segmentation kaggle'\n        self.unlabeled_data_folder = '/kaggle/input/floodnet-unlabeled/unsup segmentation kaggle/Train'\n        self.results_folder = os.path.join(self.project_folder, 'model_unet')\n        if not os.path.isdir(self.results_folder):\n            os.makedirs(self.results_folder)\nopt = Opt()","metadata":{"execution":{"iopub.status.busy":"2023-12-20T22:11:00.717264Z","iopub.execute_input":"2023-12-20T22:11:00.718226Z","iopub.status.idle":"2023-12-20T22:11:00.730286Z","shell.execute_reply.started":"2023-12-20T22:11:00.718187Z","shell.execute_reply":"2023-12-20T22:11:00.729149Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def set_model(opt):\n    if opt.name_net == 'unet':\n        model = U_Net(output_ch = opt.num_classes)\n        \n    if opt.name_net == 'pspnet':\n        model = smp.PSPNet('resnet34', in_channels=3, classes = opt.num_classes)\n\n    if opt.name_net == 'deeplab':\n        model = deeplabv3_resnet50(num_classes = opt.num_classes)\n   \n    criterion = nn.CrossEntropyLoss()\n    criterion_psl = nn.CrossEntropyLoss()\n    optimizer = optim.AdamW(model.parameters(), lr=opt.learning_rate)\n    \n    if opt.load_saved_model:\n        path = os.path.join(opt.path_to_pretrained_model, opt.name_net +'_best.pth')\n        checkpoint = (torch.load(path,map_location=torch.device('cpu')))\n        model.load_state_dict(checkpoint['model']) \n        \n        \n    if torch.cuda.is_available():\n        model = model.cuda()\n        criterion = criterion.cuda()\n        cudnn.benchmark = True\n\n    return model, criterion, criterion_psl, optimizer","metadata":{"execution":{"iopub.status.busy":"2023-12-20T22:11:00.731967Z","iopub.execute_input":"2023-12-20T22:11:00.732711Z","iopub.status.idle":"2023-12-20T22:11:00.746133Z","shell.execute_reply.started":"2023-12-20T22:11:00.732671Z","shell.execute_reply":"2023-12-20T22:11:00.745026Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def save_model(model, optimizer, opt, epoch, save_file):\n    print('==> Saving...')\n    state = {\n        'opt': opt,\n        'model': model.state_dict(),\n        'optimizer': optimizer.state_dict(),\n        'epoch': epoch,\n    }\n    torch.save(state, save_file)\n    del state","metadata":{"execution":{"iopub.status.busy":"2023-12-20T22:11:00.747503Z","iopub.execute_input":"2023-12-20T22:11:00.74787Z","iopub.status.idle":"2023-12-20T22:11:00.760005Z","shell.execute_reply.started":"2023-12-20T22:11:00.747834Z","shell.execute_reply":"2023-12-20T22:11:00.759094Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def set_loader(opt):\n    \n    train_transform = T.Compose([\n        T.RandomHorizontalFlip(),\n        T.RandomVerticalFlip(),\n        T.Resize((opt.resize_height, opt.resize_width)),\n        T.ToTensor(),\n        T.Normalize(mean=opt.mean, std=opt.std)\n    ])\n    \n    val_transform = T.Compose([\n        T.Resize((opt.resize_height, opt.resize_width)),\n        T.ToTensor(),\n        T.Normalize(mean=opt.mean, std=opt.std)\n    ])\n    train_target_transform = T.Compose([\n        T.RandomHorizontalFlip(),\n        T.RandomVerticalFlip(),\n        T.Resize((opt.resize_height, opt.resize_width)),\n        T.PILToTensor(),\n        ])\n        \n    val_target_transform = T.Compose([\n        T.Resize((opt.resize_height, opt.resize_width)),\n        T.PILToTensor(),\n        ])\n\n    train_dir = opt.labeled_data_folder + '/Train'\n    val_dir = opt.labeled_data_folder + '/Val'\n    unsup_train_dir = opt.unlabeled_data_folder +'/image'\n    train_dataset = FloodNetDataset_Labeled(train_dir, transform=train_transform , target_transform=train_target_transform)\n    validation_dataset = FloodNetDataset_Labeled(val_dir, transform=val_transform , target_transform=val_target_transform)\n    unsup_train_dataset = FloodNetDataset_Unlabeled(unsup_train_dir, transform=train_transform)\n    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=opt.batch_size, shuffle=True)\n    test_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=opt.batch_size, shuffle=True)\n    unsup_train_loader =  torch.utils.data.DataLoader(unsup_train_dataset, batch_size=opt.b_factor * opt.batch_size, shuffle=True)\n\n    return train_loader, test_loader, unsup_train_loader","metadata":{"execution":{"iopub.status.busy":"2023-12-20T22:11:00.76366Z","iopub.execute_input":"2023-12-20T22:11:00.76431Z","iopub.status.idle":"2023-12-20T22:11:00.776342Z","shell.execute_reply.started":"2023-12-20T22:11:00.764277Z","shell.execute_reply":"2023-12-20T22:11:00.775179Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def test(model, test_loader, criterion, opt):\n    model.eval()\n    val_loss = 0\n    val_dice = 0\n    total_num = 0\n    with torch.no_grad():\n        for image, mask in test_loader:\n            if torch.cuda.is_available():\n                image = image.cuda(non_blocking=True)\n                mask = mask.cuda(non_blocking=True)\n                \n            if opt.name_net == 'deeplab':\n                output = model(image)['out'] # with deeplab from torch\n            else:\n                output = model(image)\n                \n            mask = torch.squeeze(mask, dim = 1)\n            loss = criterion(output, mask.long()) # mask.long() if using cross entropy\n            total_num += mask.shape[0]\n            val_loss += loss.item() * mask.shape[0]\n            dice = dice_coef(output.argmax(dim=1), mask)\n            val_dice += dice\n    \n    val_loss = val_loss / total_num      \n    val_dice = val_dice / len(test_loader)\n    print(\"validation loss\", val_loss)\n    print(\"validation DICE coefficient\", val_dice) \n    \n    return val_loss, val_dice","metadata":{"execution":{"iopub.status.busy":"2023-12-20T22:11:00.777853Z","iopub.execute_input":"2023-12-20T22:11:00.7783Z","iopub.status.idle":"2023-12-20T22:11:00.791598Z","shell.execute_reply.started":"2023-12-20T22:11:00.778268Z","shell.execute_reply":"2023-12-20T22:11:00.790669Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train(model, train_loader, test_loader, unsup_train_loader, criterion, criterion_psl, optimizer, epoch, opt):\n    model.train()\n    total_loss, total_num = 0.0, 0\n    idx = 0\n    \n    if epoch< opt.supervised_epochs:\n        # for image, mask in train_loader:\n        for image, mask in train_loader:\n            optimizer.zero_grad()\n            # print(torch.unique(mask)) # Must be integers\n            if torch.cuda.is_available():\n                image = image.cuda(non_blocking=True)\n                mask = mask.cuda(non_blocking=True)\n            # forward + backward + optimize\n            if opt.name_net == 'deeplab':\n                output = model(image)['out'] # with deeplab from torch\n            else:\n                output = model(image)\n                \n            mask = torch.squeeze(mask, dim = 1)\n            # print('mask shape', mask.shape)\n            # print('output shape', output.shape)\n            loss = (1/image.shape[0]) * criterion(output, mask.long()) # mask.long() if using cross entropy\n            loss.backward()\n            optimizer.step()\n            total_num += mask.shape[0]\n            total_loss += loss.item() * mask.shape[0]\n        \n        if (idx + 1) % opt.print_freq == 0:\n            print('Fully_supervised-Train Epoch: [{}/{}], lr: {:.6f}, Loss: {}'.format(epoch, opt.epochs,\n                                                                    optimizer.param_groups[0]['lr'],\n                                                                    total_loss / total_num))\n            sys.stdout.flush()\n        idx += 1\n    else:\n        \n        for (image, mask), (image_nomask) in zip(train_loader, unsup_train_loader):\n            optimizer.zero_grad()\n            # print(torch.unique(mask)) # Must be integers\n            if torch.cuda.is_available():\n                image = image.cuda(non_blocking=True)\n                mask = mask.cuda(non_blocking=True)\n                image_nomask = image_nomask.cuda(non_blocking=True)\n                \n            # forward + backward + optimize\n            if opt.name_net == 'deeplab':\n                output = model(image)['out'] #with deeplab from torch\n                pseudo_output =  model(image_nomask)['out'] #with deeplab from torch\n\n            else:\n                output = model(image)\n                pseudo_output =  model(image_nomask)\n                \n            mask = torch.squeeze(mask, dim = 1)\n            pseudo_label = pseudo_output.argmax(1)\n           \n            cv_coeff = (epoch - opt.supervised_epochs)/(opt.epochs - opt.supervised_epochs)\n            loss = (1/image.shape[0]) * criterion(output, mask.long()) + (1/image_nomask.shape[0]) * cv_coeff * opt.alpha * criterion_psl(pseudo_output, pseudo_label.long()) # mask.long() if using cross entropy\n            loss.backward()\n            optimizer.step()\n            total_num += mask.shape[0]\n            total_loss += loss.item() * mask.shape[0]\n            if (idx + 1) % opt.print_freq == 0:\n                print('Self_supervised-Train Epoch: [{}/{}], lr: {:.6f}, Loss: {}'.format(epoch, opt.epochs,\n                                                                        optimizer.param_groups[0]['lr'],\n                                                                        total_loss / total_num))\n                sys.stdout.flush()\n            idx += 1\n    \n\n    gc.collect()\n    torch.cuda.empty_cache()\n    val_loss, val_dice = test(model, test_loader, criterion, opt)\n    print(\"train() function - epoch total_loss\", total_loss / total_num)\n    train_loss = total_loss / total_num\n    return train_loss, val_loss, val_dice ","metadata":{"execution":{"iopub.status.busy":"2023-12-20T22:11:00.793077Z","iopub.execute_input":"2023-12-20T22:11:00.793599Z","iopub.status.idle":"2023-12-20T22:11:00.813334Z","shell.execute_reply.started":"2023-12-20T22:11:00.793569Z","shell.execute_reply":"2023-12-20T22:11:00.812268Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.cuda.empty_cache()\n\n# build data loader\ntrain_loader, test_loader, unsup_train_loader = set_loader(opt)\nprint('train e test data loader created...')\n\n# define model\nmodel, criterion, criterion_psl, optimizer = set_model(opt)\nsave_file_1 = os.path.join(opt.results_folder, (str(opt.name_net) + '_best.pth'))\n\n# TRAINING\nprint(\"Training...\")\n\n# training routine\nbest_val_dice = opt.threshold_val_dice\ntrain_loss_values, val_loss_values, val_dices = [], [], []\n\nfor epoch in range(1, opt.epochs + 1):\n\n    train_loss, val_loss, val_dice = train(model, train_loader, test_loader, unsup_train_loader, criterion, criterion_psl, optimizer, epoch, opt)\n    train_loss_values.append(train_loss)\n    val_loss_values.append(val_loss)\n    val_dices.append(val_dice)\n\n    # save best model\n    if val_dice > best_val_dice:\n        print(\"saving/updating current best model at epoch=\" + str(epoch))\n        save_model(model, optimizer, opt, epoch, save_file_1)\n        best_val_dice = val_dice\n\n    save_file_2 = os.path.join(opt.results_folder, (str(opt.name_net) + '_last.pth'))\n    save_model(model, optimizer, opt, opt.epochs, save_file_2)\n\n    # save loss values and plot\n    tloss_df = pd.DataFrame(train_loss_values)\n    vloss_df = pd.DataFrame(val_loss_values)\n    dice_df = pd.DataFrame(val_dices)\n    tloss_df.to_csv(opt.results_folder +'/' + (str(opt.name_net) + '_train_loss.csv'))\n    vloss_df.to_csv(opt.results_folder +'/' + (str(opt.name_net) + '_val_loss.csv'))\n    dice_df.to_csv(opt.results_folder +'/' + (str(opt.name_net) + '_val_dice.csv'))\n\n    plt.figure(figsize=(15, 10))\n    plt.plot(train_loss_values, label = 'train loss')\n    plt.ylabel('train loss value')\n    plt.xlabel('epochs')\n    plt.savefig(opt.results_folder +'/' + str(opt.name_net) + ' _train_loss.png')\n    plt.close()\n\n    plt.figure(figsize=(15, 10))\n    plt.plot(val_loss_values, label = 'validation loss')\n    plt.ylabel('validation loss value')\n    plt.xlabel('epochs')\n    plt.savefig(opt.results_folder +'/' + str(opt.name_net) + ' _val_loss.png')\n    plt.close()\n\n    plt.figure(figsize=(15, 10))\n    plt.plot(val_dices)\n    plt.ylabel('dice value')\n    plt.xlabel('epochs')\n    plt.savefig(opt.results_folder +'/' + str(opt.name_net) + ' _val_dice.png')\n    plt.close()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-20T22:11:00.814921Z","iopub.execute_input":"2023-12-20T22:11:00.815292Z","iopub.status.idle":"2023-12-20T23:06:59.634938Z","shell.execute_reply.started":"2023-12-20T22:11:00.815265Z","shell.execute_reply":"2023-12-20T23:06:59.633762Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot results\n\nfrom matplotlib.colors import ListedColormap\n\ncustom_colors = [[0, 0, 0], \n                [1, 0, 0],  \n                [1, 0.75, 0],   \n                [0, 0.3, 0.7], \n                [0.6, 0.6, 0.6],   \n                [0, 0.5, 1],   \n                [0, 0.85, 0],   \n                [1, 0, 1], \n                [0.7, 0.7, 0.9], \n                [0.1, 0.55, 0.3]]\n\ncolor_names = ['background', 'building-flooded', 'building non-flooded', 'road flooded', 'road non-flooded', 'water', 'tree', 'vehicle', 'pool', 'grass']\ncustom_cmap = ListedColormap(custom_colors)\n\ndef unnormalize(tensor, mean = [-0.2417,  0.8531,  0.1789], std = [0.9023, 1.1647, 1.3271]):\n    \"\"\"\n    Unnormalizes a tensor given mean and standard deviation.\n    \n    Args:\n        tensor (torch.Tensor): Input tensor to be unnormalized.\n        mean (float or sequence): Mean value(s) for unnormalization.\n        std (float or sequence): Standard deviation value(s) for unnormalization.\n        \n    Returns:\n        torch.Tensor: Unnormalized tensor.\n    \"\"\"\n    if not torch.is_tensor(tensor):\n        raise TypeError(\"Input tensor should be a torch.Tensor\")\n    \n    mean = torch.tensor(mean, device=tensor.device, dtype=tensor.dtype)\n    std = torch.tensor(std, device=tensor.device, dtype=tensor.dtype)\n    \n    unnormalized_tensor = tensor * std + mean\n    return unnormalized_tensor\n\nmodel.eval()\n\nval_transform = T.Compose([\n    T.Resize((opt.resize_height, opt.resize_width)),\n    T.ToTensor(),\n    T.Normalize(mean=opt.mean, std=opt.std)\n])\nval_target_transform = T.Compose([\n    T.Resize((opt.resize_height, opt.resize_width)),\n    T.PILToTensor(),\n])\n\nim1 = Image.open('/kaggle/input/floodnet-labeled/segmentation kaggle/segmentation kaggle/Val/6651.jpg')\nim2 = Image.open('/kaggle/input/floodnet-labeled/segmentation kaggle/segmentation kaggle/Val/7488.jpg')\nim3 = Image.open('/kaggle/input/floodnet-labeled/segmentation kaggle/segmentation kaggle/Val/6734.jpg')\n\nmask1 = Image.open('/kaggle/input/floodnet-labeled/segmentation kaggle/segmentation kaggle/Val/6651_lab.png')\nmask2 = Image.open('/kaggle/input/floodnet-labeled/segmentation kaggle/segmentation kaggle/Val/7488_lab.png')\nmask3 = Image.open('/kaggle/input/floodnet-labeled/segmentation kaggle/segmentation kaggle/Val/6734_lab.png')\n\nim1 = val_transform(im1)\nim2 = val_transform(im2)\nim3 = val_transform(im3)\n\nmask1 = val_target_transform(mask1)\nmask2 = val_target_transform(mask2)\nmask3 = val_target_transform(mask3)\n\nif torch.cuda.is_available():\n    im1 = im1.cuda(non_blocking=True)\n    #mask1 = mask1.cuda(non_blocking=True)\n    im2 = im2.cuda(non_blocking=True)\n    #mask2 = mask2.cuda(non_blocking=True)\n    im3 = im3.cuda(non_blocking=True)\n    #mask3 = mask3.cuda(non_blocking=True)\n    \nif opt.name_net == 'deeplab': \n    pred1 = model(im1[None,:,:,:])['out']\n    pred2 = model(im2[None,:,:,:])['out']\n    pred3 = model(im3[None,:,:,:])['out']\nelse:\n    pred1 = model(im1[None,:,:,:])\n    pred2 = model(im2[None,:,:,:])\n    pred3 = model(im3[None,:,:,:])\n    \npred1 = torch.squeeze(pred1)\npred1 = pred1.argmax(0).squeeze()\npred1 = pred1.cpu().detach().numpy()\npred2 = torch.squeeze(pred2)\npred2 = pred2.argmax(0).squeeze()\npred2 = pred2.cpu().detach().numpy()\npred3 = torch.squeeze(pred3)\npred3 = pred3.argmax(0).squeeze()\npred3 = pred3.cpu().detach().numpy()\n\nfig , ax =  plt.subplots(3, 3, figsize=(18, 18))\nax[0][0].set_title('Image')\nax[0][1].set_title('Label')\nax[0][2].set_title('Prediction')\nax[1][0].set_title('Image')\nax[1][1].set_title('Label')\nax[1][2].set_title('Prediction')\nax[2][0].set_title('Image')\nax[2][1].set_title('Label')\nax[2][2].set_title('Prediction')\nax[0][0].imshow(np.squeeze(unnormalize(np.transpose(im1.squeeze().cpu(),(1,2,0)))))\nax[0][1].imshow(mask1.squeeze(), cmap = custom_cmap, vmin = 0, vmax = 9)\nax[0][2].imshow(pred1.squeeze(), cmap = custom_cmap, vmin = 0, vmax = 9)\nax[1][0].imshow(np.squeeze(unnormalize(np.transpose(im2.squeeze().cpu(),(1,2,0)))))\nax[1][1].imshow(mask2.squeeze(), cmap = custom_cmap, vmin = 0, vmax = 9)\nax[1][2].imshow(pred2.squeeze(), cmap = custom_cmap, vmin = 0, vmax = 9)\nax[2][0].imshow(np.squeeze(unnormalize(np.transpose(im3.squeeze().cpu(),(1,2,0)))))\nax[2][1].imshow(mask3.squeeze(), cmap = custom_cmap, vmin = 0, vmax = 9)\nax[2][2].imshow(pred3.squeeze(), cmap = custom_cmap, vmin = 0, vmax = 9)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-20T23:06:59.636418Z","iopub.execute_input":"2023-12-20T23:06:59.636925Z","iopub.status.idle":"2023-12-20T23:07:05.70541Z","shell.execute_reply.started":"2023-12-20T23:06:59.636887Z","shell.execute_reply":"2023-12-20T23:07:05.703967Z"},"trusted":true},"outputs":[],"execution_count":null}]}